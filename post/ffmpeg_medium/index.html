<!DOCTYPE html>
<html lang="en-us" dir="ltr">
    <head><meta charset='utf-8'>
<meta name='viewport' content='width=device-width, initial-scale=1'><meta name='description' content="ffmpeg中级开发\rH264解码 H264编码 AAC编码 AAC解码 常见结构体\rlibavcodec/avcodec.h //头文件 编解码 AVCodec 编码器结构体 avcodec_alloc_context3() avcodec_free_context() AVCodecContext编解码器上下文 串联不同的函数之间的上下文 AVFrame 解码后的帧 结构体的分配与释放：av_frame_alloc() av_frame_free() 解码步骤\r查找解码器（avcodec_find_decoder）\n打开解码器（avcodec_open2）\n解码（avcodec_decode_video2）\n#include &lt;libavutil/log.h&gt;\r#include &lt;libavutil/opt.h&gt;\r#include &lt;libavformat/avformat.h&gt;\r#include &lt;libavcodec/avcodec.h&gt;\r#include &lt;stdio.h&gt;\rstatic void encode(AVCodecContext *ctx, AVFrame *frame, AVPacket *pkt, FILE *fp){\rint ret = -1;\r// 1.编码\rret = avcodec_send_frame(ctx,frame);\rif(ret &lt; 0){\rav_log(NULL,AV_LOG_ERROR,&#34;coundn&#39;t send frame %s\\n&#34;,av_err2str(ret));\rgoto _END;\r}\r// 2.获取编码后的数据\rwhile (ret &gt;= 0)\r{\rret = avcodec_receive_packet(ctx,pkt);\rif (ret == AVERROR(EAGAIN) || ret == AVERROR_EOF){\rreturn;\r} else if (ret &lt; 0){\rav_log(NULL,AV_LOG_ERROR,&#34;coundn&#39;t receive packet %s\\n&#34;,av_err2str(ret));\rgoto _END;\r}\r// 3.写入文件\rfwrite(pkt-&gt;data,1,pkt-&gt;size,fp);\rav_packet_unref(pkt);\r}\rreturn;\r_END:\rif(pkt) av_packet_unref(pkt);\rif(frame) av_frame_unref(frame);\rif(ctx) avcodec_free_context(&amp;ctx);\rif(fp) fclose(fp);\rreturn;\r}\rint main(int argc, char** argv){\rAVCodec *codec;\rAVCodecContext *ctx;\rAVFrame *frame = NULL;\rAVPacket *pkt = NULL;\rint ret = -1;\rav_log_set_level(AV_LOG_DEBUG);\rif(argc &lt; 3){\rprintf(&#34;Usage: %s &lt;file&gt; &lt;codecname&gt;\\n&#34;, argv[0]);\rgoto _ERROR;\r}\rchar* dst = argv[1];\rchar* codecname = argv[2];\r// 2、查找编码器\rcodec = avcodec_find_encoder_by_name(codecname);\rif(!codec){\rav_log(NULL,AV_LOG_ERROR,&#34;coundn&#39;t find codec %s&#34;,codecname);\rgoto _ERROR;\r}\r// 3. 编码器上下文\rctx = avcodec_alloc_context3(codec);\rif(!ctx) {\rav_log(NULL,AV_LOG_ERROR,&#34;coundn&#39;t alloc codec context&#34;);\rgoto _ERROR;\r}\r// 4. 设置编码器参数\rctx-&gt;width = 640;\rctx-&gt;height = 480;\rctx-&gt;bit_rate = 500000;\rctx-&gt;time_base = (AVRational){1,25};\rctx-&gt;framerate = (AVRational){25,1};\rctx-&gt;gop_size = 10;\rctx-&gt;max_b_frames = 1;\rctx-&gt;pix_fmt = AV_PIX_FMT_YUV420P;\r// h264 私有属性\rif (codec-&gt;id == AV_CODEC_ID_H264){\rav_opt_set(ctx-&gt;priv_data,&#34;preset&#34;,&#34;slow&#34;,0);\r}\r// 5.绑定编码器上下文和编码器\rret = avcodec_open2(ctx,codec,NULL);\rif(ret &lt; 0){\rav_log(NULL,AV_LOG_ERROR,&#34;coundn&#39;t open codec %s&#34;,av_err2str(ret));\rgoto _ERROR;\r}\r// 6. 打开文件\rFILE *fp = fopen(dst,&#34;wb&#34;);\rif(!fp){\rav_log(NULL,AV_LOG_ERROR,&#34;coundn&#39;t open file %s&#34;,dst);\rgoto _ERROR;\r}\r// 7. 创建AVFrame\r// 创建的只是外壳 不能真正存储文件\rframe = av_frame_alloc();\rif(!frame){\rav_log(NULL,AV_LOG_ERROR,&#34;coundn&#39;t alloc frame&#34;);\rgoto _ERROR;\r}\rframe-&gt;format = ctx-&gt;pix_fmt;\rframe-&gt;width = ctx-&gt;width;\rframe-&gt;height = ctx-&gt;height;\rret = av_frame_get_buffer(frame,0);\rif(ret &lt; 0){\rav_log(NULL,AV_LOG_ERROR,&#34;coundn&#39;t alloc frame buffer %s\\n&#34;,av_err2str(ret));\rgoto _ERROR;\r}\r// 8. 创建AVPacket\rpkt = av_packet_alloc();\rif(!pkt){\rav_log(NULL,AV_LOG_ERROR,&#34;coundn&#39;t alloc packet&#34;);\rgoto _ERROR;\r}\r// 9. 生成视频内容\rfor(int i = 0; i &lt; 10; i++){\rret = av_frame_make_writable(frame);\rif(ret &lt; 0) {\rbreak;\r}\rfor(int y = 0; y &lt; frame-&gt;height; y++){\rfor(int x = 0; x &lt; frame-&gt;width; x++){\rframe-&gt;data[0][y*frame-&gt;linesize[0] + x] = x + y + i*3;\rframe-&gt;data[1][y/2*frame-&gt;linesize[1] + x/2] = 128 + y + i*2;\rframe-&gt;data[2][y/2*frame-&gt;linesize[2] + x/2] = 64 + x + i*5;\r}\r}\rframe-&gt;pts = i;\rencode(ctx,frame,pkt,fp);\r}\rencode(ctx,NULL,pkt,fp);\r_ERROR:\rif(ctx){\ravcodec_free_context(&amp;ctx);\r}\rif(frame){\rav_frame_free(&amp;frame);\r}\rif(pkt){\rav_packet_free(&amp;pkt);\r}\rif(fp){\rfclose(fp);\r}\rreturn 0;\r} YUV介绍\rYUV是通过亮度和色彩来分别代表像素的格式，其中“Y”表示明亮度（Luminance或Luma），也就是灰度值；而“U”和“V”表示的则是色度。在实际使用中，使用的格式一般是YCbCr，其中Y是指亮度分量，Cb指蓝色色度分量，而Cr指红色色度分量。在格式上面有很多取样格式。 YUV 4:4:4采样，每一个Y对应一组UV分量,一个YUV占8+8+8 = 24bits 3个字节。\rYUV 4:2:2采样，每两个Y共用一组UV分量,一个YUV占8+4+4 = 16bits 2个字节。\rYUV 4:2:0采样，每四个Y共用一组UV分量,一个YUV占8+2+2 = 12bits 1.5个字节。 我们最常见的YUV420P和YUV420SP都是基于4:2:0采样的，所以如果图片的宽为width，高为heigth，在内存中占的空间为width * height * 3 / 2，其中前width * height的空间存放Y分量，接着width * height / 4存放U分量，最后width * height / 4存放V分量。\n">
<title>ffmpeg中级开发</title>

<link rel='canonical' href='https://898311543.github.io/post/ffmpeg_medium/'>

<link rel="stylesheet" href="/scss/style.min.b9c8156d464c343bdacaf14a871581fb94cbbdb9dd5cbce4ba017361187cc930.css"><meta property='og:title' content="ffmpeg中级开发">
<meta property='og:description' content="ffmpeg中级开发\rH264解码 H264编码 AAC编码 AAC解码 常见结构体\rlibavcodec/avcodec.h //头文件 编解码 AVCodec 编码器结构体 avcodec_alloc_context3() avcodec_free_context() AVCodecContext编解码器上下文 串联不同的函数之间的上下文 AVFrame 解码后的帧 结构体的分配与释放：av_frame_alloc() av_frame_free() 解码步骤\r查找解码器（avcodec_find_decoder）\n打开解码器（avcodec_open2）\n解码（avcodec_decode_video2）\n#include &lt;libavutil/log.h&gt;\r#include &lt;libavutil/opt.h&gt;\r#include &lt;libavformat/avformat.h&gt;\r#include &lt;libavcodec/avcodec.h&gt;\r#include &lt;stdio.h&gt;\rstatic void encode(AVCodecContext *ctx, AVFrame *frame, AVPacket *pkt, FILE *fp){\rint ret = -1;\r// 1.编码\rret = avcodec_send_frame(ctx,frame);\rif(ret &lt; 0){\rav_log(NULL,AV_LOG_ERROR,&#34;coundn&#39;t send frame %s\\n&#34;,av_err2str(ret));\rgoto _END;\r}\r// 2.获取编码后的数据\rwhile (ret &gt;= 0)\r{\rret = avcodec_receive_packet(ctx,pkt);\rif (ret == AVERROR(EAGAIN) || ret == AVERROR_EOF){\rreturn;\r} else if (ret &lt; 0){\rav_log(NULL,AV_LOG_ERROR,&#34;coundn&#39;t receive packet %s\\n&#34;,av_err2str(ret));\rgoto _END;\r}\r// 3.写入文件\rfwrite(pkt-&gt;data,1,pkt-&gt;size,fp);\rav_packet_unref(pkt);\r}\rreturn;\r_END:\rif(pkt) av_packet_unref(pkt);\rif(frame) av_frame_unref(frame);\rif(ctx) avcodec_free_context(&amp;ctx);\rif(fp) fclose(fp);\rreturn;\r}\rint main(int argc, char** argv){\rAVCodec *codec;\rAVCodecContext *ctx;\rAVFrame *frame = NULL;\rAVPacket *pkt = NULL;\rint ret = -1;\rav_log_set_level(AV_LOG_DEBUG);\rif(argc &lt; 3){\rprintf(&#34;Usage: %s &lt;file&gt; &lt;codecname&gt;\\n&#34;, argv[0]);\rgoto _ERROR;\r}\rchar* dst = argv[1];\rchar* codecname = argv[2];\r// 2、查找编码器\rcodec = avcodec_find_encoder_by_name(codecname);\rif(!codec){\rav_log(NULL,AV_LOG_ERROR,&#34;coundn&#39;t find codec %s&#34;,codecname);\rgoto _ERROR;\r}\r// 3. 编码器上下文\rctx = avcodec_alloc_context3(codec);\rif(!ctx) {\rav_log(NULL,AV_LOG_ERROR,&#34;coundn&#39;t alloc codec context&#34;);\rgoto _ERROR;\r}\r// 4. 设置编码器参数\rctx-&gt;width = 640;\rctx-&gt;height = 480;\rctx-&gt;bit_rate = 500000;\rctx-&gt;time_base = (AVRational){1,25};\rctx-&gt;framerate = (AVRational){25,1};\rctx-&gt;gop_size = 10;\rctx-&gt;max_b_frames = 1;\rctx-&gt;pix_fmt = AV_PIX_FMT_YUV420P;\r// h264 私有属性\rif (codec-&gt;id == AV_CODEC_ID_H264){\rav_opt_set(ctx-&gt;priv_data,&#34;preset&#34;,&#34;slow&#34;,0);\r}\r// 5.绑定编码器上下文和编码器\rret = avcodec_open2(ctx,codec,NULL);\rif(ret &lt; 0){\rav_log(NULL,AV_LOG_ERROR,&#34;coundn&#39;t open codec %s&#34;,av_err2str(ret));\rgoto _ERROR;\r}\r// 6. 打开文件\rFILE *fp = fopen(dst,&#34;wb&#34;);\rif(!fp){\rav_log(NULL,AV_LOG_ERROR,&#34;coundn&#39;t open file %s&#34;,dst);\rgoto _ERROR;\r}\r// 7. 创建AVFrame\r// 创建的只是外壳 不能真正存储文件\rframe = av_frame_alloc();\rif(!frame){\rav_log(NULL,AV_LOG_ERROR,&#34;coundn&#39;t alloc frame&#34;);\rgoto _ERROR;\r}\rframe-&gt;format = ctx-&gt;pix_fmt;\rframe-&gt;width = ctx-&gt;width;\rframe-&gt;height = ctx-&gt;height;\rret = av_frame_get_buffer(frame,0);\rif(ret &lt; 0){\rav_log(NULL,AV_LOG_ERROR,&#34;coundn&#39;t alloc frame buffer %s\\n&#34;,av_err2str(ret));\rgoto _ERROR;\r}\r// 8. 创建AVPacket\rpkt = av_packet_alloc();\rif(!pkt){\rav_log(NULL,AV_LOG_ERROR,&#34;coundn&#39;t alloc packet&#34;);\rgoto _ERROR;\r}\r// 9. 生成视频内容\rfor(int i = 0; i &lt; 10; i++){\rret = av_frame_make_writable(frame);\rif(ret &lt; 0) {\rbreak;\r}\rfor(int y = 0; y &lt; frame-&gt;height; y++){\rfor(int x = 0; x &lt; frame-&gt;width; x++){\rframe-&gt;data[0][y*frame-&gt;linesize[0] + x] = x + y + i*3;\rframe-&gt;data[1][y/2*frame-&gt;linesize[1] + x/2] = 128 + y + i*2;\rframe-&gt;data[2][y/2*frame-&gt;linesize[2] + x/2] = 64 + x + i*5;\r}\r}\rframe-&gt;pts = i;\rencode(ctx,frame,pkt,fp);\r}\rencode(ctx,NULL,pkt,fp);\r_ERROR:\rif(ctx){\ravcodec_free_context(&amp;ctx);\r}\rif(frame){\rav_frame_free(&amp;frame);\r}\rif(pkt){\rav_packet_free(&amp;pkt);\r}\rif(fp){\rfclose(fp);\r}\rreturn 0;\r} YUV介绍\rYUV是通过亮度和色彩来分别代表像素的格式，其中“Y”表示明亮度（Luminance或Luma），也就是灰度值；而“U”和“V”表示的则是色度。在实际使用中，使用的格式一般是YCbCr，其中Y是指亮度分量，Cb指蓝色色度分量，而Cr指红色色度分量。在格式上面有很多取样格式。 YUV 4:4:4采样，每一个Y对应一组UV分量,一个YUV占8+8+8 = 24bits 3个字节。\rYUV 4:2:2采样，每两个Y共用一组UV分量,一个YUV占8+4+4 = 16bits 2个字节。\rYUV 4:2:0采样，每四个Y共用一组UV分量,一个YUV占8+2+2 = 12bits 1.5个字节。 我们最常见的YUV420P和YUV420SP都是基于4:2:0采样的，所以如果图片的宽为width，高为heigth，在内存中占的空间为width * height * 3 / 2，其中前width * height的空间存放Y分量，接着width * height / 4存放U分量，最后width * height / 4存放V分量。\n">
<meta property='og:url' content='https://898311543.github.io/post/ffmpeg_medium/'>
<meta property='og:site_name' content='Shubin'>
<meta property='og:type' content='article'><meta property='article:section' content='Post' /><meta property='article:published_time' content='2024-10-17T01:02:59&#43;08:00'/><meta property='article:modified_time' content='2024-10-17T01:02:59&#43;08:00'/>
<meta name="twitter:title" content="ffmpeg中级开发">
<meta name="twitter:description" content="ffmpeg中级开发\rH264解码 H264编码 AAC编码 AAC解码 常见结构体\rlibavcodec/avcodec.h //头文件 编解码 AVCodec 编码器结构体 avcodec_alloc_context3() avcodec_free_context() AVCodecContext编解码器上下文 串联不同的函数之间的上下文 AVFrame 解码后的帧 结构体的分配与释放：av_frame_alloc() av_frame_free() 解码步骤\r查找解码器（avcodec_find_decoder）\n打开解码器（avcodec_open2）\n解码（avcodec_decode_video2）\n#include &lt;libavutil/log.h&gt;\r#include &lt;libavutil/opt.h&gt;\r#include &lt;libavformat/avformat.h&gt;\r#include &lt;libavcodec/avcodec.h&gt;\r#include &lt;stdio.h&gt;\rstatic void encode(AVCodecContext *ctx, AVFrame *frame, AVPacket *pkt, FILE *fp){\rint ret = -1;\r// 1.编码\rret = avcodec_send_frame(ctx,frame);\rif(ret &lt; 0){\rav_log(NULL,AV_LOG_ERROR,&#34;coundn&#39;t send frame %s\\n&#34;,av_err2str(ret));\rgoto _END;\r}\r// 2.获取编码后的数据\rwhile (ret &gt;= 0)\r{\rret = avcodec_receive_packet(ctx,pkt);\rif (ret == AVERROR(EAGAIN) || ret == AVERROR_EOF){\rreturn;\r} else if (ret &lt; 0){\rav_log(NULL,AV_LOG_ERROR,&#34;coundn&#39;t receive packet %s\\n&#34;,av_err2str(ret));\rgoto _END;\r}\r// 3.写入文件\rfwrite(pkt-&gt;data,1,pkt-&gt;size,fp);\rav_packet_unref(pkt);\r}\rreturn;\r_END:\rif(pkt) av_packet_unref(pkt);\rif(frame) av_frame_unref(frame);\rif(ctx) avcodec_free_context(&amp;ctx);\rif(fp) fclose(fp);\rreturn;\r}\rint main(int argc, char** argv){\rAVCodec *codec;\rAVCodecContext *ctx;\rAVFrame *frame = NULL;\rAVPacket *pkt = NULL;\rint ret = -1;\rav_log_set_level(AV_LOG_DEBUG);\rif(argc &lt; 3){\rprintf(&#34;Usage: %s &lt;file&gt; &lt;codecname&gt;\\n&#34;, argv[0]);\rgoto _ERROR;\r}\rchar* dst = argv[1];\rchar* codecname = argv[2];\r// 2、查找编码器\rcodec = avcodec_find_encoder_by_name(codecname);\rif(!codec){\rav_log(NULL,AV_LOG_ERROR,&#34;coundn&#39;t find codec %s&#34;,codecname);\rgoto _ERROR;\r}\r// 3. 编码器上下文\rctx = avcodec_alloc_context3(codec);\rif(!ctx) {\rav_log(NULL,AV_LOG_ERROR,&#34;coundn&#39;t alloc codec context&#34;);\rgoto _ERROR;\r}\r// 4. 设置编码器参数\rctx-&gt;width = 640;\rctx-&gt;height = 480;\rctx-&gt;bit_rate = 500000;\rctx-&gt;time_base = (AVRational){1,25};\rctx-&gt;framerate = (AVRational){25,1};\rctx-&gt;gop_size = 10;\rctx-&gt;max_b_frames = 1;\rctx-&gt;pix_fmt = AV_PIX_FMT_YUV420P;\r// h264 私有属性\rif (codec-&gt;id == AV_CODEC_ID_H264){\rav_opt_set(ctx-&gt;priv_data,&#34;preset&#34;,&#34;slow&#34;,0);\r}\r// 5.绑定编码器上下文和编码器\rret = avcodec_open2(ctx,codec,NULL);\rif(ret &lt; 0){\rav_log(NULL,AV_LOG_ERROR,&#34;coundn&#39;t open codec %s&#34;,av_err2str(ret));\rgoto _ERROR;\r}\r// 6. 打开文件\rFILE *fp = fopen(dst,&#34;wb&#34;);\rif(!fp){\rav_log(NULL,AV_LOG_ERROR,&#34;coundn&#39;t open file %s&#34;,dst);\rgoto _ERROR;\r}\r// 7. 创建AVFrame\r// 创建的只是外壳 不能真正存储文件\rframe = av_frame_alloc();\rif(!frame){\rav_log(NULL,AV_LOG_ERROR,&#34;coundn&#39;t alloc frame&#34;);\rgoto _ERROR;\r}\rframe-&gt;format = ctx-&gt;pix_fmt;\rframe-&gt;width = ctx-&gt;width;\rframe-&gt;height = ctx-&gt;height;\rret = av_frame_get_buffer(frame,0);\rif(ret &lt; 0){\rav_log(NULL,AV_LOG_ERROR,&#34;coundn&#39;t alloc frame buffer %s\\n&#34;,av_err2str(ret));\rgoto _ERROR;\r}\r// 8. 创建AVPacket\rpkt = av_packet_alloc();\rif(!pkt){\rav_log(NULL,AV_LOG_ERROR,&#34;coundn&#39;t alloc packet&#34;);\rgoto _ERROR;\r}\r// 9. 生成视频内容\rfor(int i = 0; i &lt; 10; i++){\rret = av_frame_make_writable(frame);\rif(ret &lt; 0) {\rbreak;\r}\rfor(int y = 0; y &lt; frame-&gt;height; y++){\rfor(int x = 0; x &lt; frame-&gt;width; x++){\rframe-&gt;data[0][y*frame-&gt;linesize[0] + x] = x + y + i*3;\rframe-&gt;data[1][y/2*frame-&gt;linesize[1] + x/2] = 128 + y + i*2;\rframe-&gt;data[2][y/2*frame-&gt;linesize[2] + x/2] = 64 + x + i*5;\r}\r}\rframe-&gt;pts = i;\rencode(ctx,frame,pkt,fp);\r}\rencode(ctx,NULL,pkt,fp);\r_ERROR:\rif(ctx){\ravcodec_free_context(&amp;ctx);\r}\rif(frame){\rav_frame_free(&amp;frame);\r}\rif(pkt){\rav_packet_free(&amp;pkt);\r}\rif(fp){\rfclose(fp);\r}\rreturn 0;\r} YUV介绍\rYUV是通过亮度和色彩来分别代表像素的格式，其中“Y”表示明亮度（Luminance或Luma），也就是灰度值；而“U”和“V”表示的则是色度。在实际使用中，使用的格式一般是YCbCr，其中Y是指亮度分量，Cb指蓝色色度分量，而Cr指红色色度分量。在格式上面有很多取样格式。 YUV 4:4:4采样，每一个Y对应一组UV分量,一个YUV占8+8+8 = 24bits 3个字节。\rYUV 4:2:2采样，每两个Y共用一组UV分量,一个YUV占8+4+4 = 16bits 2个字节。\rYUV 4:2:0采样，每四个Y共用一组UV分量,一个YUV占8+2+2 = 12bits 1.5个字节。 我们最常见的YUV420P和YUV420SP都是基于4:2:0采样的，所以如果图片的宽为width，高为heigth，在内存中占的空间为width * height * 3 / 2，其中前width * height的空间存放Y分量，接着width * height / 4存放U分量，最后width * height / 4存放V分量。\n">
    </head>
    <body class="
    article-page
    ">
    <script>
        (function() {
            const colorSchemeKey = 'StackColorScheme';
            if(!localStorage.getItem(colorSchemeKey)){
                localStorage.setItem(colorSchemeKey, "auto");
            }
        })();
    </script><script>
    (function() {
        const colorSchemeKey = 'StackColorScheme';
        const colorSchemeItem = localStorage.getItem(colorSchemeKey);
        const supportDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches === true;

        if (colorSchemeItem == 'dark' || colorSchemeItem === 'auto' && supportDarkMode) {
            

            document.documentElement.dataset.scheme = 'dark';
        } else {
            document.documentElement.dataset.scheme = 'light';
        }
    })();
</script>
<div class="container main-container flex on-phone--column compact"><aside class="sidebar left-sidebar sticky ">
    <button class="hamburger hamburger--spin" type="button" id="toggle-menu" aria-label="Toggle Menu">
        <span class="hamburger-box">
            <span class="hamburger-inner"></span>
        </span>
    </button>

    <header>
        
            
            <figure class="site-avatar">
                <a href="/">
                
                    
                    
                    
                        
                        <img src="/img/avatar_hu13739649187745961479.png" width="300"
                            height="300" class="site-logo" loading="lazy" alt="Avatar">
                    
                
                </a>
                
            </figure>
            
        
        
        <div class="site-meta">
            <h1 class="site-name"><a href="/">Shubin</a></h1>
            <h2 class="site-description"></h2>
        </div>
    </header><ol class="menu" id="main-menu">
        
        
        <li class="menu-bottom-section">
            <ol class="menu">

                
                    <li id="dark-mode-toggle">
                        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="8" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="16" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                        <span>Dark Mode</span>
                    </li>
                
            </ol>
        </li>
    </ol>
</aside>

    

            <main class="main full-width">
    <article class="main-article">
    <header class="article-header">

    <div class="article-details">
    

    <div class="article-title-wrapper">
        <h2 class="article-title">
            <a href="/post/ffmpeg_medium/">ffmpeg中级开发</a>
        </h2>
    
        
    </div>

    
    
    
    
    <footer class="article-time">
        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <path d="M11.795 21h-6.795a2 2 0 0 1 -2 -2v-12a2 2 0 0 1 2 -2h12a2 2 0 0 1 2 2v4" />
  <circle cx="18" cy="18" r="4" />
  <path d="M15 3v4" />
  <path d="M7 3v4" />
  <path d="M3 11h16" />
  <path d="M18 16.496v1.504l1 1" />
</svg>
                <time class="article-time--published">Oct 17, 2024</time>
            </div>
        

        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <polyline points="12 7 12 12 15 15" />
</svg>



                <time class="article-time--reading">
                    8 minute read
                </time>
            </div>
        
    </footer>
    

    
</div>

</header>

    <section class="article-content">
    
    
    <h1 id="ffmpeg中级开发">ffmpeg中级开发
</h1><ul>
<li>H264解码</li>
<li>H264编码</li>
<li>AAC编码</li>
<li>AAC解码</li>
</ul>
<h3 id="常见结构体">常见结构体
</h3><pre tabindex="0"><code>libavcodec/avcodec.h //头文件 编解码
</code></pre><ul>
<li>AVCodec 编码器结构体
<ul>
<li><code>avcodec_alloc_context3()</code> <code>avcodec_free_context()</code></li>
</ul>
</li>
<li>AVCodecContext编解码器上下文 串联不同的函数之间的上下文</li>
<li>AVFrame 解码后的帧
<ul>
<li>结构体的分配与释放：<code>av_frame_alloc() av_frame_free()</code></li>
</ul>
</li>
</ul>
<h3 id="解码步骤">解码步骤
</h3><ul>
<li>
<p>查找解码器（<code>avcodec_find_decoder</code>）</p>
</li>
<li>
<p>打开解码器（<code>avcodec_open2</code>）</p>
</li>
<li>
<p>解码（<code>avcodec_decode_video2</code>）</p>
</li>
</ul>
<pre tabindex="0"><code>#include &lt;libavutil/log.h&gt;
#include &lt;libavutil/opt.h&gt;
#include &lt;libavformat/avformat.h&gt;
#include &lt;libavcodec/avcodec.h&gt;
#include &lt;stdio.h&gt;

static void encode(AVCodecContext *ctx, AVFrame *frame, AVPacket *pkt, FILE *fp){
    int ret = -1;
    // 1.编码
    ret = avcodec_send_frame(ctx,frame);
    if(ret &lt; 0){
        av_log(NULL,AV_LOG_ERROR,&#34;coundn&#39;t send frame %s\n&#34;,av_err2str(ret));
        goto _END;
    }
    // 2.获取编码后的数据
    while (ret &gt;= 0)
    {
       ret = avcodec_receive_packet(ctx,pkt);
       if (ret == AVERROR(EAGAIN) || ret == AVERROR_EOF){
           return;
       } else if (ret &lt; 0){
           av_log(NULL,AV_LOG_ERROR,&#34;coundn&#39;t receive packet %s\n&#34;,av_err2str(ret));
           goto _END;
       }
        // 3.写入文件
        fwrite(pkt-&gt;data,1,pkt-&gt;size,fp);
        av_packet_unref(pkt);
    }
    

    return;
_END:
    if(pkt) av_packet_unref(pkt);
    if(frame) av_frame_unref(frame);
    if(ctx) avcodec_free_context(&amp;ctx);
    if(fp) fclose(fp);
    return;
}

int main(int argc, char** argv){
    AVCodec *codec;
    AVCodecContext *ctx;
    AVFrame *frame = NULL;
    AVPacket *pkt = NULL;
    int ret = -1;
    av_log_set_level(AV_LOG_DEBUG);
    if(argc &lt; 3){
        printf(&#34;Usage: %s &lt;file&gt; &lt;codecname&gt;\n&#34;, argv[0]);
        goto _ERROR;
    }
    char* dst = argv[1];
    char* codecname = argv[2];
    // 2、查找编码器
    codec = avcodec_find_encoder_by_name(codecname);
    if(!codec){
        av_log(NULL,AV_LOG_ERROR,&#34;coundn&#39;t find codec %s&#34;,codecname);
        goto _ERROR;
    }
    // 3. 编码器上下文
    ctx = avcodec_alloc_context3(codec);
    if(!ctx) {
        av_log(NULL,AV_LOG_ERROR,&#34;coundn&#39;t alloc codec context&#34;);
        goto _ERROR;
    }
    // 4. 设置编码器参数
    ctx-&gt;width = 640;
    ctx-&gt;height = 480;
    ctx-&gt;bit_rate = 500000;
    ctx-&gt;time_base = (AVRational){1,25};
    ctx-&gt;framerate = (AVRational){25,1};
    ctx-&gt;gop_size = 10;
    ctx-&gt;max_b_frames = 1;
    ctx-&gt;pix_fmt = AV_PIX_FMT_YUV420P;
    // h264 私有属性
    if (codec-&gt;id == AV_CODEC_ID_H264){
        av_opt_set(ctx-&gt;priv_data,&#34;preset&#34;,&#34;slow&#34;,0);
    }
    // 5.绑定编码器上下文和编码器
    ret = avcodec_open2(ctx,codec,NULL);
    if(ret &lt; 0){
        av_log(NULL,AV_LOG_ERROR,&#34;coundn&#39;t open codec %s&#34;,av_err2str(ret));
        goto _ERROR;
    }
    // 6. 打开文件
    FILE *fp = fopen(dst,&#34;wb&#34;);
    if(!fp){
        av_log(NULL,AV_LOG_ERROR,&#34;coundn&#39;t open file %s&#34;,dst);
        goto _ERROR;
    }
    // 7. 创建AVFrame
    // 创建的只是外壳 不能真正存储文件
    frame = av_frame_alloc();
    if(!frame){
        av_log(NULL,AV_LOG_ERROR,&#34;coundn&#39;t alloc frame&#34;);
        goto _ERROR;
    }
    frame-&gt;format = ctx-&gt;pix_fmt;
    frame-&gt;width = ctx-&gt;width;
    frame-&gt;height = ctx-&gt;height;
    ret = av_frame_get_buffer(frame,0);
    if(ret &lt; 0){
        av_log(NULL,AV_LOG_ERROR,&#34;coundn&#39;t alloc frame buffer %s\n&#34;,av_err2str(ret));
        goto _ERROR;
    }
    // 8. 创建AVPacket
    pkt = av_packet_alloc();
    if(!pkt){
        av_log(NULL,AV_LOG_ERROR,&#34;coundn&#39;t alloc packet&#34;);
        goto _ERROR;
    }
    // 9. 生成视频内容
    for(int i = 0; i &lt; 10; i++){
        ret = av_frame_make_writable(frame);
        if(ret &lt; 0) {
            break;
        }
        for(int y = 0; y &lt; frame-&gt;height; y++){
            for(int x = 0; x &lt; frame-&gt;width; x++){
                frame-&gt;data[0][y*frame-&gt;linesize[0] + x] = x + y + i*3;
                frame-&gt;data[1][y/2*frame-&gt;linesize[1] + x/2] = 128 + y + i*2;
                frame-&gt;data[2][y/2*frame-&gt;linesize[2] + x/2] = 64 + x + i*5;
            }
        }
        frame-&gt;pts = i;
        encode(ctx,frame,pkt,fp);
    }
    encode(ctx,NULL,pkt,fp);
    _ERROR:
        if(ctx){
            avcodec_free_context(&amp;ctx);
        }
        if(frame){
            av_frame_free(&amp;frame);
        }
        if(pkt){
            av_packet_free(&amp;pkt);
        }
        if(fp){
            fclose(fp);
        }
        return 0;
}
</code></pre><h2 id="yuv介绍">YUV介绍
</h2><ul>
<li>YUV是通过亮度和色彩来分别代表像素的格式，其中“Y”表示明亮度（Luminance或Luma），也就是灰度值；而“U”和“V”表示的则是色度。在实际使用中，使用的格式一般是YCbCr，其中Y是指亮度分量，Cb指蓝色色度分量，而Cr指红色色度分量。在格式上面有很多取样格式。</li>
</ul>
<pre tabindex="0"><code>YUV 4:4:4采样，每一个Y对应一组UV分量,一个YUV占8+8+8 = 24bits 3个字节。
YUV 4:2:2采样，每两个Y共用一组UV分量,一个YUV占8+4+4 = 16bits 2个字节。
YUV 4:2:0采样，每四个Y共用一组UV分量,一个YUV占8+2+2 = 12bits 1.5个字节。
</code></pre><p>我们最常见的<code>YUV420P和YUV420SP</code>都是基于<code>4:2:0</code>采样的，所以如果图片的宽为<code>width</code>，高为<code>heigth</code>，在内存中占的空间为<code>width * height * 3 / 2</code>，其中前<code>width * height</code>的空间存放<code>Y分量</code>，接着<code>width * height / 4</code>存放<code>U分量</code>，最后<code>width * height / 4</code>存放<code>V分量</code>。</p>
<h3 id="yuv420pyu12和yv12格式">YUV420P(YU12和YV12)格式
</h3><p><code>YUV420P</code>又叫<code>plane平面模式</code>，<code>Y , U , V</code>分别在不同平面，也就是有三个平面，它是<code>YUV标准格式4：2：0</code>，主要分为：<code>YU12</code>和<code>YV12</code></p>
<p>
<img class="img-fluid" src="../../assets/20181119225805899.png" alt='img' />
</p>
<p>
<img class="img-fluid" src="../../assets/2018111923013322.png" alt='img' />
</p>
<ul>
<li>
<p>YU12格式</p>
<ul>
<li>在<code>Android平台下</code>也叫做<code>I420格式</code>，首先是所有<code>Y值</code>，然后是所有<code>U值</code>，最终是所有<code>V值</code>。</li>
</ul>
<p>
<img class="img-fluid" src="../../assets/2018112012345555.png" alt='img' />
</p>
<p><code>YU12：亮度(行×列) + U(行×列/4) + V(行×列/4)</code></p>
</li>
<li>
<p>YV12格式</p>
<ul>
<li><code>YV12格式</code>与<code>YU12</code>基本相同，首先是所有<code>Y值</code>，然后是所有<code>V值</code>，最后是所有<code>U值</code>。只要注意从适当的位置提取<code>U和V值</code>，<code>YU12和YV12</code>都可以使用相同的算法进行处理。</li>
</ul>
<p>
<img class="img-fluid" src="../../assets/20181120123516554.png" alt='img' />
</p>
<p><code>YV12：亮度Y(行×列) + V(行×列/4) + U(行×列/4</code></p>
</li>
</ul>
<h3 id="生成图片代码">生成图片代码
</h3><pre tabindex="0"><code>#include &lt;stdio.h&gt;
#include &lt;libavutil/log.h&gt;
#include &lt;libavutil/avutil.h&gt;
#include &lt;libavformat/avio.h&gt;
#include &lt;libavformat/avformat.h&gt;
#include &lt;libavcodec/avcodec.h&gt;


static void savePic(AVFrame *frame, char *filename){
    FILE *f = fopen(filename, &#34;wb&#34;);
    fprintf(f, &#34;P5\n%d %d\n255\n&#34;, frame-&gt;width, frame-&gt;height);
    // fwrite(const void *ptr, size_t size, size_t nmemb, FILE *stream);
    // size 每个元素的大小 nmemb 元素的个数  
    for (int i = 0; i &lt; frame-&gt;height; i++)
    {
        fwrite(frame-&gt;data[0]+i*frame-&gt;linesize[0], 1, frame-&gt;width, f);
    }
    
    fclose(f);
}

static int decode(AVCodecContext *ctx, AVFrame *frame, AVPacket *pkt, char *filename){
    int ret;
    char filename_filled[1024];
    ret = avcodec_send_packet(ctx, pkt);
    if(ret &lt; 0){
        av_log(NULL, AV_LOG_ERROR, &#34;Error sending a packet for decoding ret = %d %d\n&#34;, ret,AVERROR(EINVAL));
        return ret;
    }

    while(ret &gt;= 0){
        ret = avcodec_receive_frame(ctx, frame);
        if(ret == AVERROR(EAGAIN) || ret == AVERROR_EOF){
            return 0;
        }else if(ret &lt; 0){
            av_log(NULL, AV_LOG_ERROR, &#34;Error during decoding\n&#34;);
            return ret;
        }
        printf(&#34;frame_number = %d\n&#34;, ctx-&gt;frame_number);
        snprintf(filename_filled, sizeof(filename)+5, &#34;%s-%d&#34;, filename, ctx-&gt;frame_number);
        savePic(frame, filename_filled);
        fflush(stdout);
    }
    return 0;
}


int main(int argc, char *argv[]){
    // 1、处理一些参数
    // 2、打开文件
    // 3、从多媒体文件中找到音频流
    // 4、打开目的文件的上下文
    // 5、为目的文件打开音频流
    // 6、设置输出音频参数
    // 7、写多媒体文件头
    // 8、循环读取音频流，写入目的文件
    // 9、写文件尾
    // 10、 释放资源

    char* src;
    char* dst;
    AVCodecContext *ctx;
    AVFormatContext *fmt_ctx;
    AVStream *in_stream = NULL, *out_stream = NULL;
    const static AVCodec *codec;
    AVPacket *pkt;
    AVFrame *frame;
    int index = -1;
    av_log_set_level(AV_LOG_DEBUG);
    if (argc &lt; 3) {
        printf(&#34;Usage: %s &lt;input file&gt; &lt;output file&gt;\n&#34;, argv[0]);
        exit(1);
    }
    src = argv[1];
    dst = argv[2];
    fmt_ctx = avformat_alloc_context();
    // 第一个null 表示相关的格式 最后一个参数为选项 如果返回值为负值表示失败
    int ret = avformat_open_input(&amp;fmt_ctx, src, NULL, NULL);
    if (ret &lt; 0) {
        av_log(NULL, AV_LOG_ERROR, &#34;Could not open source file %s\n&#34;, src);
        exit(1);
    }

    if ((ret = avformat_find_stream_info(fmt_ctx, NULL)) &lt; 0) {
        av_log(NULL, AV_LOG_ERROR, &#34;Cannot find stream information\n&#34;);
        return ret;
    }
    index = av_find_best_stream(fmt_ctx, AVMEDIA_TYPE_VIDEO, -1, -1, NULL, 0);
    if(index &lt; 0){
        // 第一参数可以指定为上下文
        av_log(fmt_ctx, AV_LOG_ERROR, &#34;Could not find %s stream in input file %s\n&#34;, av_get_media_type_string(AVMEDIA_TYPE_VIDEO), src);
        goto _ERROR;
    }
    codec = avcodec_find_decoder(fmt_ctx-&gt;streams[index]-&gt;codecpar-&gt;codec_id);
    if(codec == NULL){
        av_log(fmt_ctx, AV_LOG_ERROR, &#34;Could not find codec \n&#34;);
        goto _ERROR;
    }
    ctx = avcodec_alloc_context3(NULL);
    if(ctx == NULL){
        av_log(fmt_ctx, AV_LOG_ERROR, &#34;Could not allocate codec context\n&#34;);
        goto _ERROR;
    }
    // 重要 不要写avcodec_parameters_copy 否则会导致coredump
    avcodec_parameters_to_context(ctx, fmt_ctx-&gt;streams[index]-&gt;codecpar);
    // 将解码器和解码器上下文连接
    ret = avcodec_open2(ctx, codec, NULL);
    if(ret &lt; 0){
        av_log(fmt_ctx, AV_LOG_ERROR, &#34;Could not open codec\n&#34;);
        goto _ERROR;
    }
    frame = av_frame_alloc();
    if(frame == NULL){
        av_log(fmt_ctx, AV_LOG_ERROR, &#34;Could not allocate frame\n&#34;);
        goto _ERROR;
    }
    pkt = av_packet_alloc();
    if(pkt == NULL){
        av_log(fmt_ctx, AV_LOG_ERROR, &#34;Could not allocate packet\n&#34;);
        goto _ERROR;
    }
    int pkt_index = 0;
    while(av_read_frame(fmt_ctx, pkt) &gt;= 0){
        if(pkt-&gt;stream_index == index){
            // pkt_index ++;
            decode(ctx,frame, pkt,dst);
            if(pkt_index ++ &gt; 10)
                break;
            // av_packet_unref(pkt);
        }
    }
    decode(ctx,frame, NULL,dst);

_ERROR:
    if(fmt_ctx != NULL){
        avformat_close_input(&amp;fmt_ctx);
    }
    if(ctx) {
        avcodec_free_context(&amp;ctx);
        ctx = NULL;
    }
    if(frame){
        av_frame_free(&amp;frame);
        frame = NULL;
    }
    if(pkt){
        av_packet_free(&amp;pkt);
        pkt = NULL;
    }
    
    return 0;
}
</code></pre><pre tabindex="0"><code>#include &lt;stdio.h&gt;
#include &lt;libavutil/log.h&gt;
#include &lt;libavutil/avutil.h&gt;
#include &lt;libavformat/avio.h&gt;
#include &lt;libavformat/avformat.h&gt;
#include &lt;libavcodec/avcodec.h&gt;
#include &lt;libswscale/swscale.h&gt;

#define WORD uint16_t
#define DWORD uint32_t
#define LONG  int32_t
#pragma pack(2)
typedef struct tagBITMAPINFOHEADER {
  DWORD biSize;
  LONG  biWidth;
  LONG  biHeight;
  WORD  biPlanes;
  WORD  biBitCount;
  DWORD biCompression;
  DWORD biSizeImage;
  LONG  biXPelsPerMeter;
  LONG  biYPelsPerMeter;
  DWORD biClrUsed;
  DWORD biClrImportant;
} BITMAPINFOHEADER, *LPBITMAPINFOHEADER, *PBITMAPINFOHEADER;

typedef struct tagBITMAPFILEHEADER {
  WORD  bfType;
  DWORD bfSize;
  WORD  bfReserved1;
  WORD  bfReserved2;
  DWORD bfOffBits;
} BITMAPFILEHEADER, *LPBITMAPFILEHEADER, *PBITMAPFILEHEADER;

// 1、先进行转换，将yuv420p转为rgb24
// 2、构造BITMAPINFORHEADER
// 3、构造BITMAPFILEHEADER
// 4、将数据写入文件 
// 5、释放资源
static void saveBmp(struct SwsContext *sws_ctx, AVFrame *frame, int width, int height, char *filename){
    AVFrame *frame_rgb24 = av_frame_alloc();
    FILE *f = fopen(filename, &#34;wb&#34;);
    int image_size = width * height * 3;
    int ret;
    frame_rgb24-&gt;width = width;
    frame_rgb24-&gt;height = height;
    frame_rgb24-&gt;format = AV_PIX_FMT_RGB24;
    ret = av_frame_get_buffer(frame_rgb24, 0);
    if(ret &lt; 0){
        av_log(NULL, AV_LOG_ERROR, &#34;Error allocating the frame data ret = %d\n&#34;, ret);
        return;
    }
    sws_scale(sws_ctx, (const uint8_t * const*)frame-&gt;data, frame-&gt;linesize, 0, frame-&gt;height, frame_rgb24-&gt;data, frame_rgb24-&gt;linesize);
    printf(&#34;image_size = %d width = %d height = %d &#34;,image_size, width, height);
    BITMAPINFOHEADER infoheader;
    infoheader.biSize = sizeof(BITMAPINFOHEADER);
    infoheader.biWidth = width;
    infoheader.biHeight = height * (-1); // 高度坐标相反
    infoheader.biBitCount = 24;
    infoheader.biCompression = 0;
    infoheader.biSizeImage = 0;
    infoheader.biClrImportant = 0;
    infoheader.biClrUsed = 0;
    infoheader.biXPelsPerMeter = 0;
    infoheader.biYPelsPerMeter = 0;
    infoheader.biPlanes = 1;
    BITMAPFILEHEADER fileheader;
    fileheader.bfType = 0x4D42; // &#34;BM&#34;
    fileheader.bfSize = sizeof(BITMAPFILEHEADER) + sizeof(BITMAPINFOHEADER) + image_size;
    fileheader.bfOffBits = sizeof(BITMAPFILEHEADER) + sizeof(BITMAPINFOHEADER);
    fwrite(&amp;fileheader, sizeof(BITMAPFILEHEADER), 1, f);
    fwrite(&amp;infoheader, sizeof(BITMAPINFOHEADER), 1, f);
    fwrite(frame_rgb24-&gt;data[0], 1, image_size, f);
    fclose(f);
    av_freep(&amp;frame_rgb24-&gt;data[0]);
    av_frame_free(frame_rgb24);
}

static void savePic(AVFrame *frame, char *filename){
    FILE *f = fopen(filename, &#34;wb&#34;);
    fprintf(f, &#34;P5\n%d %d\n255\n&#34;, frame-&gt;width, frame-&gt;height);
    // fwrite(const void *ptr, size_t size, size_t nmemb, FILE *stream);
    // size 每个元素的大小 nmemb 元素的个数  
    for (int i = 0; i &lt; frame-&gt;height; i++)
    {
        fwrite(frame-&gt;data[0]+i*frame-&gt;linesize[0], 1, frame-&gt;width, f);
    }
    
    fclose(f);
}

static int decode(AVCodecContext *ctx, struct SwsContext *sws_ctx, AVFrame *frame, AVPacket *pkt, char *filename){
    int ret;
    char filename_filled[1024];
    ret = avcodec_send_packet(ctx, pkt);
    if(ret &lt; 0){
        av_log(NULL, AV_LOG_ERROR, &#34;Error sending a packet for decoding ret = %d %d\n&#34;, ret,AVERROR(EINVAL));
        return ret;
    }

    while(ret &gt;= 0){
        ret = avcodec_receive_frame(ctx, frame);
        if(ret == AVERROR(EAGAIN) || ret == AVERROR_EOF){
            return 0;
        }else if(ret &lt; 0){
            av_log(NULL, AV_LOG_ERROR, &#34;Error during decoding\n&#34;);
            return ret;
        }
        printf(&#34;frame_number = %d\n&#34;, ctx-&gt;frame_number);
        snprintf(filename_filled, sizeof(filename)+5, &#34;%s-%d.bmp&#34;, filename, ctx-&gt;frame_number);
        // savePic(frame, filename_filled);
        saveBmp(sws_ctx,frame,640, 360, filename_filled);
        fflush(stdout);
    }
    return 0;
}


int main(int argc, char *argv[]){
    // 1、处理一些参数
    // 2、打开文件
    // 3、从多媒体文件中找到音频流
    // 4、打开目的文件的上下文
    // 5、为目的文件打开音频流
    // 6、设置输出音频参数
    // 7、写多媒体文件头
    // 8、循环读取音频流，写入目的文件
    // 9、写文件尾
    // 10、 释放资源

    char* src;
    char* dst;
    AVCodecContext *ctx;
    AVFormatContext *fmt_ctx;
    AVStream *in_stream = NULL, *out_stream = NULL;
    const static AVCodec *codec;
    AVPacket *pkt;
    AVFrame *frame;
    struct SwsContext *sws_ctx = NULL;

    int index = -1;
    av_log_set_level(AV_LOG_DEBUG);
    if (argc &lt; 3) {
        printf(&#34;Usage: %s &lt;input file&gt; &lt;output file&gt;\n&#34;, argv[0]);
        exit(1);
    }
    src = argv[1];
    dst = argv[2];
    fmt_ctx = avformat_alloc_context();
    // 第一个null 表示相关的格式 最后一个参数为选项 如果返回值为负值表示失败
    int ret = avformat_open_input(&amp;fmt_ctx, src, NULL, NULL);
    if (ret &lt; 0) {
        av_log(NULL, AV_LOG_ERROR, &#34;Could not open source file %s\n&#34;, src);
        exit(1);
    }

    if ((ret = avformat_find_stream_info(fmt_ctx, NULL)) &lt; 0) {
        av_log(NULL, AV_LOG_ERROR, &#34;Cannot find stream information\n&#34;);
        return ret;
    }
    index = av_find_best_stream(fmt_ctx, AVMEDIA_TYPE_VIDEO, -1, -1, NULL, 0);
    if(index &lt; 0){
        // 第一参数可以指定为上下文
        av_log(fmt_ctx, AV_LOG_ERROR, &#34;Could not find %s stream in input file %s\n&#34;, av_get_media_type_string(AVMEDIA_TYPE_VIDEO), src);
        goto _ERROR;
    }
    codec = avcodec_find_decoder(fmt_ctx-&gt;streams[index]-&gt;codecpar-&gt;codec_id);
    if(codec == NULL){
        av_log(fmt_ctx, AV_LOG_ERROR, &#34;Could not find codec \n&#34;);
        goto _ERROR;
    }
    ctx = avcodec_alloc_context3(NULL);
    if(ctx == NULL){
        av_log(fmt_ctx, AV_LOG_ERROR, &#34;Could not allocate codec context\n&#34;);
        goto _ERROR;
    }
    // 重要 不要写avcodec_parameters_copy 否则会导致coredump
    avcodec_parameters_to_context(ctx, fmt_ctx-&gt;streams[index]-&gt;codecpar);
    // printf(&#34;width %d height %d&#34;, ctx-&gt;width,ctx-&gt;height);
    // 图像转换
    sws_ctx = sws_getContext(
                        ctx-&gt;width, 
                        ctx-&gt;height, 
                        AV_PIX_FMT_YUV420P, 
                        640, 
                        360, 
                        AV_PIX_FMT_BGR24,
                        SWS_BICUBIC, NULL, NULL, NULL);
    if (sws_ctx == NULL){
        av_log(fmt_ctx, AV_LOG_ERROR, &#34;Could not initialize the conversion context\n&#34;);
        goto _ERROR;
    }
    // 将解码器和解码器上下文连接
    ret = avcodec_open2(ctx, codec, NULL);
    if(ret &lt; 0){
        av_log(fmt_ctx, AV_LOG_ERROR, &#34;Could not open codec\n&#34;);
        goto _ERROR;
    }
    frame = av_frame_alloc();
    if(frame == NULL){
        av_log(fmt_ctx, AV_LOG_ERROR, &#34;Could not allocate frame\n&#34;);
        goto _ERROR;
    }
    pkt = av_packet_alloc();
    if(pkt == NULL){
        av_log(fmt_ctx, AV_LOG_ERROR, &#34;Could not allocate packet\n&#34;);
        goto _ERROR;
    }
    int pkt_index = 0;
    while(av_read_frame(fmt_ctx, pkt) &gt;= 0){
        if(pkt-&gt;stream_index == index){
            // pkt_index ++;
            decode(ctx,sws_ctx,frame, pkt,dst);
            if(pkt_index ++ &gt; 10)
                break;
            // av_packet_unref(pkt);
        }
    }
    decode(ctx,sws_ctx,frame, NULL,dst);

_ERROR:
    if(fmt_ctx != NULL){
        avformat_close_input(&amp;fmt_ctx);
    }
    if(ctx) {
        avcodec_free_context(&amp;ctx);
        ctx = NULL;
    }
    if(frame){
        av_frame_free(&amp;frame);
        frame = NULL;
    }
    if(pkt){
        av_packet_free(&amp;pkt);
        pkt = NULL;
    }
    if(sws_ctx){
        sws_freeContext(sws_ctx);
        sws_ctx = NULL;
    }
    return 0;
}
</code></pre>
</section>


    <footer class="article-footer">
    

    </footer>


    
</article>

    

    

     
    
        
    

    <footer class="site-footer">
    <section class="copyright">
        &copy; 
        
        2024 Shubin
    </section>
    
    <section class="powerby">
        Built with <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> <br />
        Theme <b><a href="https://github.com/CaiJimmy/hugo-theme-stack" target="_blank" rel="noopener" data-version="3.27.0">Stack</a></b> designed by <a href="https://jimmycai.com" target="_blank" rel="noopener">Jimmy</a>
    </section>
</footer>


    
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    
    <div class="pswp__bg"></div>

    
    <div class="pswp__scroll-wrap">

        
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                
                
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo="crossorigin="anonymous"
                defer
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU="crossorigin="anonymous"
                defer
                >
            </script><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css"crossorigin="anonymous"
            ><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css"crossorigin="anonymous"
            >

            </main>
        </div>
        <script 
                src="https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js"integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z&#43;KMkF24hUW8WePSA9HM="crossorigin="anonymous"
                
                >
            </script><script type="text/javascript" src="/ts/main.js" defer></script>
<script>
    (function () {
        const customFont = document.createElement('link');
        customFont.href = "https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap";

        customFont.type = "text/css";
        customFont.rel = "stylesheet";

        document.head.appendChild(customFont);
    }());
</script>

    </body>
</html>
