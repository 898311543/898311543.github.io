<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Shubin</title>
        <link>https://898311543.github.io/</link>
        <description>Recent content on Shubin</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <lastBuildDate>Thu, 17 Oct 2024 11:27:55 +0800</lastBuildDate><atom:link href="https://898311543.github.io/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Golang学习记录</title>
        <link>https://898311543.github.io/post/golang_learning/</link>
        <pubDate>Thu, 17 Oct 2024 11:27:55 +0800</pubDate>
        
        <guid>https://898311543.github.io/post/golang_learning/</guid>
        <description>&lt;h1 id=&#34;golang-知识记录&#34;&gt;&lt;strong&gt;Golang 知识记录&lt;/strong&gt;
&lt;/h1&gt;&lt;h2 id=&#34;例子&#34;&gt;例子
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;写响应头长度&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;		fmt.Println(&amp;#34;abnormalFileServer: zeroLength&amp;#34;)
		w.Header().Set(&amp;#34;Content-Length&amp;#34;, &amp;#34;0&amp;#34;)
		w.Write([]byte(&amp;#34;This is the actual response body&amp;#34;))
		return
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;写状态码&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;		fmt.Println(&amp;#34;abnormalFileServer: 404&amp;#34;)
		http.Error(w, &amp;#34;abnormalFileServer&amp;#34;, http.StatusNotFound)
		return
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;不同访问次数的访问结果不同（第一次访问成功，其他访问失败）&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;		query := r.URL.Query()
		val := query.Get(&amp;#34;command&amp;#34;)
		switch  val {
			case &amp;#34;clear&amp;#34;:
				accessCount = 0
				return
		}
		if accessCount &amp;gt; 0 {
			
			http.Error(w, &amp;#34;abnormalFileServer&amp;#34;, http.StatusInternalServerError)
			fmt.Printf(&amp;#34;onlyFirstSuccess.mp4 : %d fails\n&amp;#34;,accessCount)
			accessCount ++
			return
		}
		http.ServeFile(w, r, &amp;#34;file_folder/1MB.mp4&amp;#34;)
		fmt.Printf(&amp;#34;onlyFirstSuccess.mp4 : %d success\n&amp;#34;,accessCount)
		accessCount ++
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;删除请求header中的特定参数&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;			r.Header.Del(&amp;#34;Range&amp;#34;)             // 删除参数
			http.ServeFile(w, r, &amp;#34;file_folder/1022KB.mp4&amp;#34;)
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;golang-server-基本用法&#34;&gt;golang server 基本用法
&lt;/h2&gt;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;package main

import (
    &amp;#34;fmt&amp;#34;
    &amp;#34;net/http&amp;#34;
)
// handler 函数有两个参数，`http.ResponseWriter` 和 `http.Request`。 response writer 被用于写入 HTTP 响应数据，这里我们简单的返回 “hello\n”。
func hello(w http.ResponseWriter, req *http.Request) {

    fmt.Fprintf(w, &amp;#34;hello\n&amp;#34;)
}
// 这个 handler 稍微复杂一点， 我们需要读取的 HTTP 请求 header 中的所有内容，并将他们输出至 response body。
func headers(w http.ResponseWriter, req *http.Request) {

    for name, headers := range req.Header {
        for _, h := range headers {
            fmt.Fprintf(w, &amp;#34;%v: %v\n&amp;#34;, name, h)
        }
    }
}

func main() {

    http.HandleFunc(&amp;#34;/hello&amp;#34;, hello)
    http.HandleFunc(&amp;#34;/headers&amp;#34;, headers)

    http.ListenAndServe(&amp;#34;:8090&amp;#34;, nil)
}
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;关于路径&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;http.HandleFunc(&amp;quot;/globFiles/&amp;quot;, globFiles) 路径最后携带/ 能够通配/globFiles开头的所有路径&lt;/li&gt;
&lt;li&gt;如果不携带只能精确匹配这个指定的路径&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;读取GET的参数&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;获取query&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;q := r.URL.Query()
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;读取参数&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;id := query[&amp;quot;id&amp;quot;][0] &lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;id := query.Get(&amp;quot;id&amp;quot;)&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;map遍历&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;for key, value := range req.URL.Query() {
  fmt.Fprintf(w, &amp;#34;%v: %v\n&amp;#34;, key, value)
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;获取 &lt;code&gt;application/x-www-form-urlencoded&lt;/code&gt;类型的参数&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;req.ParseForm()
username := request.Form.Get(&amp;#34;username&amp;#34;)
password := request.Form.Get(&amp;#34;password&amp;#34;)
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;curl命令&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;curl -X POST https://reqbin.com/echo/post/form
   -H &amp;#34;Content-Type: application/x-www-form-urlencoded&amp;#34; 
   -d &amp;#34;param1=value1&amp;amp;param2=value2&amp;#34; 
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;获取&lt;code&gt;application/json &lt;/code&gt;类型的参数&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;func  json_decode(w http.ResponseWriter, req *http.Request) {
	decoder := json.NewDecoder(req.Body)
	var v map[string]interface{}
	err := decoder.Decode(&amp;amp;v)
	if err != nil {
		panic(err)
	}
	for key, value := range v {
		switch value := value.(type) {
		case string:
			fmt.Printf(&amp;#34;Key: %s, Value: %s, Type: string\n&amp;#34;, key, value)
		case int:
			fmt.Printf(&amp;#34;Key: %s, Value: %d, Type: int\n&amp;#34;, key, value)
		case bool:
			fmt.Printf(&amp;#34;Key: %s, Value: %t, Type: bool\n&amp;#34;, key, value)
		case float64:
			fmt.Printf(&amp;#34;Key: %s, Value: %f, Type: float64\n&amp;#34;, key, value)
		case []string:
			fmt.Printf(&amp;#34;Key: %s, Value: %v, Type: []string\n&amp;#34;, key, value)
		default:
			fmt.Printf(&amp;#34;Key: %s, Value: %v, Type: unknown\n&amp;#34;, key, value)
		}
	}
	fmt.Fprintf(w,&amp;#34;{\&amp;#34;code\&amp;#34;:0}&amp;#34;)
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;context&#34;&gt;Context
&lt;/h3&gt;&lt;p&gt;平时在 Go 工程中开发中，几乎所有服务端（例如：HTTP Server）的默认实现，都在处理请求时新起 goroutine 进行处理。&lt;/p&gt;
&lt;p&gt;但一开始存在一个问题，那就是当一个请求被取消或超时时，所有在该请求上工作的 goroutines 应该迅速退出，以便系统可以回收他们正在使用的任何资源。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;package main

import (
    &amp;#34;fmt&amp;#34;
    &amp;#34;net/http&amp;#34;
    &amp;#34;time&amp;#34;
)

func hello(w http.ResponseWriter, req *http.Request) {

    ctx := req.Context()
    fmt.Println(&amp;#34;server: hello handler started&amp;#34;)
    defer fmt.Println(&amp;#34;server: hello handler ended&amp;#34;)

    select {
    case &amp;lt;-time.After(10 * time.Second):
        fmt.Fprintf(w, &amp;#34;hello\n&amp;#34;)
    case &amp;lt;-ctx.Done():

        err := ctx.Err()
        fmt.Println(&amp;#34;server:&amp;#34;, err)
        internalError := http.StatusInternalServerError
        http.Error(w, err.Error(), internalError)
    }
}

func main() {

    http.HandleFunc(&amp;#34;/hello&amp;#34;, hello)
    http.ListenAndServe(&amp;#34;:8090&amp;#34;, nil)
}
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;客户端主动断开后，会进入ctx.Done()分支&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>ffmpeg中级开发</title>
        <link>https://898311543.github.io/post/ffmpeg_medium/</link>
        <pubDate>Thu, 17 Oct 2024 01:02:59 +0800</pubDate>
        
        <guid>https://898311543.github.io/post/ffmpeg_medium/</guid>
        <description>&lt;h1 id=&#34;ffmpeg中级开发&#34;&gt;ffmpeg中级开发
&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;H264解码&lt;/li&gt;
&lt;li&gt;H264编码&lt;/li&gt;
&lt;li&gt;AAC编码&lt;/li&gt;
&lt;li&gt;AAC解码&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;常见结构体&#34;&gt;常见结构体
&lt;/h3&gt;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;libavcodec/avcodec.h //头文件 编解码
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;AVCodec 编码器结构体
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;avcodec_alloc_context3()&lt;/code&gt; &lt;code&gt;avcodec_free_context()&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;AVCodecContext编解码器上下文 串联不同的函数之间的上下文&lt;/li&gt;
&lt;li&gt;AVFrame 解码后的帧
&lt;ul&gt;
&lt;li&gt;结构体的分配与释放：&lt;code&gt;av_frame_alloc() av_frame_free()&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;解码步骤&#34;&gt;解码步骤
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;查找解码器（&lt;code&gt;avcodec_find_decoder&lt;/code&gt;）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;打开解码器（&lt;code&gt;avcodec_open2&lt;/code&gt;）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;解码（&lt;code&gt;avcodec_decode_video2&lt;/code&gt;）&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;#include &amp;lt;libavutil/log.h&amp;gt;
#include &amp;lt;libavutil/opt.h&amp;gt;
#include &amp;lt;libavformat/avformat.h&amp;gt;
#include &amp;lt;libavcodec/avcodec.h&amp;gt;
#include &amp;lt;stdio.h&amp;gt;

static void encode(AVCodecContext *ctx, AVFrame *frame, AVPacket *pkt, FILE *fp){
    int ret = -1;
    // 1.编码
    ret = avcodec_send_frame(ctx,frame);
    if(ret &amp;lt; 0){
        av_log(NULL,AV_LOG_ERROR,&amp;#34;coundn&amp;#39;t send frame %s\n&amp;#34;,av_err2str(ret));
        goto _END;
    }
    // 2.获取编码后的数据
    while (ret &amp;gt;= 0)
    {
       ret = avcodec_receive_packet(ctx,pkt);
       if (ret == AVERROR(EAGAIN) || ret == AVERROR_EOF){
           return;
       } else if (ret &amp;lt; 0){
           av_log(NULL,AV_LOG_ERROR,&amp;#34;coundn&amp;#39;t receive packet %s\n&amp;#34;,av_err2str(ret));
           goto _END;
       }
        // 3.写入文件
        fwrite(pkt-&amp;gt;data,1,pkt-&amp;gt;size,fp);
        av_packet_unref(pkt);
    }
    

    return;
_END:
    if(pkt) av_packet_unref(pkt);
    if(frame) av_frame_unref(frame);
    if(ctx) avcodec_free_context(&amp;amp;ctx);
    if(fp) fclose(fp);
    return;
}

int main(int argc, char** argv){
    AVCodec *codec;
    AVCodecContext *ctx;
    AVFrame *frame = NULL;
    AVPacket *pkt = NULL;
    int ret = -1;
    av_log_set_level(AV_LOG_DEBUG);
    if(argc &amp;lt; 3){
        printf(&amp;#34;Usage: %s &amp;lt;file&amp;gt; &amp;lt;codecname&amp;gt;\n&amp;#34;, argv[0]);
        goto _ERROR;
    }
    char* dst = argv[1];
    char* codecname = argv[2];
    // 2、查找编码器
    codec = avcodec_find_encoder_by_name(codecname);
    if(!codec){
        av_log(NULL,AV_LOG_ERROR,&amp;#34;coundn&amp;#39;t find codec %s&amp;#34;,codecname);
        goto _ERROR;
    }
    // 3. 编码器上下文
    ctx = avcodec_alloc_context3(codec);
    if(!ctx) {
        av_log(NULL,AV_LOG_ERROR,&amp;#34;coundn&amp;#39;t alloc codec context&amp;#34;);
        goto _ERROR;
    }
    // 4. 设置编码器参数
    ctx-&amp;gt;width = 640;
    ctx-&amp;gt;height = 480;
    ctx-&amp;gt;bit_rate = 500000;
    ctx-&amp;gt;time_base = (AVRational){1,25};
    ctx-&amp;gt;framerate = (AVRational){25,1};
    ctx-&amp;gt;gop_size = 10;
    ctx-&amp;gt;max_b_frames = 1;
    ctx-&amp;gt;pix_fmt = AV_PIX_FMT_YUV420P;
    // h264 私有属性
    if (codec-&amp;gt;id == AV_CODEC_ID_H264){
        av_opt_set(ctx-&amp;gt;priv_data,&amp;#34;preset&amp;#34;,&amp;#34;slow&amp;#34;,0);
    }
    // 5.绑定编码器上下文和编码器
    ret = avcodec_open2(ctx,codec,NULL);
    if(ret &amp;lt; 0){
        av_log(NULL,AV_LOG_ERROR,&amp;#34;coundn&amp;#39;t open codec %s&amp;#34;,av_err2str(ret));
        goto _ERROR;
    }
    // 6. 打开文件
    FILE *fp = fopen(dst,&amp;#34;wb&amp;#34;);
    if(!fp){
        av_log(NULL,AV_LOG_ERROR,&amp;#34;coundn&amp;#39;t open file %s&amp;#34;,dst);
        goto _ERROR;
    }
    // 7. 创建AVFrame
    // 创建的只是外壳 不能真正存储文件
    frame = av_frame_alloc();
    if(!frame){
        av_log(NULL,AV_LOG_ERROR,&amp;#34;coundn&amp;#39;t alloc frame&amp;#34;);
        goto _ERROR;
    }
    frame-&amp;gt;format = ctx-&amp;gt;pix_fmt;
    frame-&amp;gt;width = ctx-&amp;gt;width;
    frame-&amp;gt;height = ctx-&amp;gt;height;
    ret = av_frame_get_buffer(frame,0);
    if(ret &amp;lt; 0){
        av_log(NULL,AV_LOG_ERROR,&amp;#34;coundn&amp;#39;t alloc frame buffer %s\n&amp;#34;,av_err2str(ret));
        goto _ERROR;
    }
    // 8. 创建AVPacket
    pkt = av_packet_alloc();
    if(!pkt){
        av_log(NULL,AV_LOG_ERROR,&amp;#34;coundn&amp;#39;t alloc packet&amp;#34;);
        goto _ERROR;
    }
    // 9. 生成视频内容
    for(int i = 0; i &amp;lt; 10; i++){
        ret = av_frame_make_writable(frame);
        if(ret &amp;lt; 0) {
            break;
        }
        for(int y = 0; y &amp;lt; frame-&amp;gt;height; y++){
            for(int x = 0; x &amp;lt; frame-&amp;gt;width; x++){
                frame-&amp;gt;data[0][y*frame-&amp;gt;linesize[0] + x] = x + y + i*3;
                frame-&amp;gt;data[1][y/2*frame-&amp;gt;linesize[1] + x/2] = 128 + y + i*2;
                frame-&amp;gt;data[2][y/2*frame-&amp;gt;linesize[2] + x/2] = 64 + x + i*5;
            }
        }
        frame-&amp;gt;pts = i;
        encode(ctx,frame,pkt,fp);
    }
    encode(ctx,NULL,pkt,fp);
    _ERROR:
        if(ctx){
            avcodec_free_context(&amp;amp;ctx);
        }
        if(frame){
            av_frame_free(&amp;amp;frame);
        }
        if(pkt){
            av_packet_free(&amp;amp;pkt);
        }
        if(fp){
            fclose(fp);
        }
        return 0;
}
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;yuv介绍&#34;&gt;YUV介绍
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;YUV是通过亮度和色彩来分别代表像素的格式，其中“Y”表示明亮度（Luminance或Luma），也就是灰度值；而“U”和“V”表示的则是色度。在实际使用中，使用的格式一般是YCbCr，其中Y是指亮度分量，Cb指蓝色色度分量，而Cr指红色色度分量。在格式上面有很多取样格式。&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>ffmpeg命令</title>
        <link>https://898311543.github.io/post/ffmpeg_command/</link>
        <pubDate>Wed, 16 Oct 2024 16:44:55 +0800</pubDate>
        
        <guid>https://898311543.github.io/post/ffmpeg_command/</guid>
        <description>&lt;h2 id=&#34;ffmpeg命令&#34;&gt;ffmpeg命令
&lt;/h2&gt;&lt;p&gt;





&lt;img class=&#34;img-fluid&#34; src=&#34;https://898311543.github.io/1725547140054.png&#34; alt=&#39;1725547140054&#39; /&gt;
&lt;/p&gt;
&lt;h3 id=&#34;ffmpeg-处理音视频流程&#34;&gt;ffmpeg 处理音视频流程
&lt;/h3&gt;&lt;p&gt;





&lt;img class=&#34;img-fluid&#34; src=&#34;https://898311543.github.io/image-20240905224438715.png&#34; alt=&#39;image-20240905224438715&#39; /&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;输入文件具有封装格式（将这个封装格式打开称之为解封装）-&amp;gt;解出来的格式也是编码之后的&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;编码后的数据可以进行解码，解码之后得到解码后的数据帧&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;数据帧encode之后可以得到编码数据包&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;编码之后可以输出想要的格式&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ffmpeg命令分类&#34;&gt;ffmpeg命令分类
&lt;/h2&gt;&lt;p&gt;





&lt;img class=&#34;img-fluid&#34; src=&#34;https://898311543.github.io/1725549272444.png&#34; alt=&#39;1725549272444&#39; /&gt;
&lt;/p&gt;
&lt;p&gt;





&lt;img class=&#34;img-fluid&#34; src=&#34;https://898311543.github.io/1725549351267.png&#34; alt=&#39;1725549351267&#39; /&gt;
&lt;/p&gt;
&lt;h2 id=&#34;录制命令&#34;&gt;录制命令
&lt;/h2&gt;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;ffmpeg -list_devices true -f dshow -i dummy
&lt;/code&gt;&lt;/pre&gt;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;ffmpeg -f dshow -i video=&amp;#34;USB2.0 HD UVC WebCam&amp;#34; -vcodec libx264 -preset ultrafast desktop.mkv
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;





&lt;img class=&#34;img-fluid&#34; src=&#34;https://898311543.github.io/image-20240906224126914.png&#34; alt=&#39;image-20240906224126914&#39; /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;code&gt; ffmpeg -i 东周列国：春秋篇.EP01.1996.DVDRip.x264.AC3-CMCT.mkv -vcodec copy -acodec copy a.mp4&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ffmpeg -i 东周列国：春秋篇.EP01.1996.DVDRip.x264.AC3-CMCT.mkv -vn -acodec copy a.ac3&lt;/code&gt;&lt;/p&gt;
&lt;h2 id=&#34;处理原始数据&#34;&gt;处理原始数据
&lt;/h2&gt;&lt;p&gt;生成原始数据：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;ffmpeg -i 东周列国：春秋篇.EP01.1996.DVDRip.x264.AC3-CMCT.mkv -an -c:v rawvideo -pix_fmt yuv420p out.yuv
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;由于原始数据中不包含分辨率信息，需要手动指定：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;ffplay -video_size 768x576  out.yuv
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;ffmpeg提取pcm数据：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;ffmpeg -i 东周列国：春秋篇.EP01.flv -vn -ar 44100 -ac 2 -f s16le out.pcm
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;因为不含采样率、存储方式等信息所以无法直接播放，应使用：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;ffplay -ar 44100 -f s16le out.pcm
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;滤镜命令&#34;&gt;滤镜命令
&lt;/h2&gt;&lt;p&gt;使用滤镜要使用解码后的数据，压缩后的数据是无法处理的：&lt;/p&gt;
&lt;p&gt;





&lt;img class=&#34;img-fluid&#34; src=&#34;https://898311543.github.io/image-20240907151620144.png&#34; alt=&#39;image-20240907151620144&#39; /&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;视频画面裁剪命令&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt; ffmpeg -i 东周列国：春秋篇.EP01.flv -vf crop=in_w-400:in_h-200 -c:v libx264 -c:a copy out.mp4&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ffmpeg -c:v h264_cuvid -crop 10x100x10x100 -i 东周列国：春秋篇.EP01.flv -c:v h264_nvenc -c:a copy out.mp4&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;视频长度裁剪命令&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ffmpeg -c:v h264_cuvid -crop 10x100x10x100 -i 东周列国：春秋篇.EP01.flv -ss 00:02:00 -t 10 -c:v h264_nvenc -c:a copy out.mp4 &lt;/code&gt;&lt;/li&gt;
&lt;li&gt;ss指的是裁剪开始的时间 -t指的是视频持续的时间&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ffmpeg音视频合并&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;ffmpeg -f concat -i input.txt out.flv
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;input.txt内容为‘file filename’格式&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;图片和视频互转&#34;&gt;图片和视频互转
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;视频转图片&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ffmpeg -i in.flv -r 1 -f image2 image-%3d.jpeg&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;图片转视频&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ffmpeg -i image-%3d.jpeg out.mp4&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;直播推拉流&#34;&gt;直播推/拉流
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;直播推流
&lt;ul&gt;
&lt;li&gt;ffmpeg -re -i out.mp4 -c copy -f flv rtmp://server/live/streamName
&lt;ul&gt;
&lt;li&gt;-re 减慢速度 以实际播放速度进行推流&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;直播拉流
&lt;ul&gt;
&lt;li&gt;ffmpeg -i rtmp://server/live/streamName -c copy dump.flv&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;ffmpeg-初级开发&#34;&gt;FFMPEG 初级开发
&lt;/h1&gt;&lt;h2 id=&#34;代码结构&#34;&gt;代码结构
&lt;/h2&gt;&lt;h3 id=&#34;日志系统&#34;&gt;日志系统
&lt;/h3&gt;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;#include &amp;lt;libavutil/log.h&amp;gt; //引入头文件
av_log_set_level(AV_LOG_DEBUG) //设置日志级别
av_log(NULL,AV_LOG_INFO,&amp;#34;...%s\n&amp;#34;,op)  //输入日志
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;日志级别：AV_LOG_ERROR、AV_LOG_WARNING、AV_LOG_INFO、AV_LOG_DEBUG&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;libavutil/log.h&amp;gt;

int main(int argc, char *argv[]){
    av_log_set_level(AV_LOG_ERROR);
    av_log(NULL, AV_LOG_INFO, &amp;#34;hello world\n&amp;#34;);
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;多媒体文件的基本概念&#34;&gt;多媒体文件的基本概念
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;多媒体文件其实是个容器&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在容器中有很多流（Stream/Track）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;每个流是由不同的编码器编码的、&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;流里抽出来的数据成为包&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在一个包里包含着一个或多个帧&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;几个重要的结构体&#34;&gt;几个重要的结构体
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;AVFormatContext 容器&lt;/li&gt;
&lt;li&gt;AVStream 流或者轨&lt;/li&gt;
&lt;li&gt;AVPacket 包&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;ffmpeg操作数据的基本步骤&#34;&gt;FFmpeg操作数据的基本步骤
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;解复用&lt;/li&gt;
&lt;li&gt;获取流&lt;/li&gt;
&lt;li&gt;读数据包&lt;/li&gt;
&lt;li&gt;释放资源&lt;/li&gt;
&lt;/ol&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;libavutil/log.h&amp;gt;
#include &amp;lt;libavutil/avutil.h&amp;gt;
#include &amp;lt;libavformat/avio.h&amp;gt;
#include &amp;lt;libavformat/avformat.h&amp;gt;

int main(int argc, char *argv[]){
    // 1、处理一些参数
    // 2、打开文件
    // 3、从多媒体文件中找到音频流
    // 4、打开目的文件的上下文
    // 5、为目的文件打开音频流
    // 6、设置输出音频参数
    // 7、写多媒体文件头
    // 8、循环读取音频流，写入目的文件
    // 9、写文件尾
    // 10、 释放资源

    char* src;
    char* dst;
    AVFormatContext *fmt_ctx, *ofmt_ctx;
    AVOutputFormat *outFmt;
    AVStream *in_stream = NULL, *out_stream = NULL;
    AVPacket pkt;
    int index = -1;
    av_log_set_level(AV_LOG_DEBUG);
    if (argc &amp;lt; 3) {
        printf(&amp;#34;Usage: %s &amp;lt;input file&amp;gt; &amp;lt;output file&amp;gt;\n&amp;#34;, argv[0]);
        exit(1);
    }
    src = argv[1];
    dst = argv[2];
    // 第一个null 表示相关的格式 最后一个参数为选项 如果返回值为负值表示失败
    int ret = avformat_open_input(&amp;amp;fmt_ctx, src, NULL, NULL);
    if (ret &amp;lt; 0) {
        av_log(NULL, AV_LOG_ERROR, &amp;#34;Could not open source file %s\n&amp;#34;, src);
        exit(1);
    }
    index = av_find_best_stream(fmt_ctx, AVMEDIA_TYPE_AUDIO, -1, -1, NULL, 0);
    if(index &amp;lt; 0){
        // 第一参数可以指定为上下文
        av_log(fmt_ctx, AV_LOG_ERROR, &amp;#34;Could not find %s stream in input file %s\n&amp;#34;, av_get_media_type_string(AVMEDIA_TYPE_AUDIO), src);
        goto _ERROR;
    }
    ofmt_ctx = avformat_alloc_context();
    if(ofmt_ctx == NULL){
        av_log(NULL, AV_LOG_ERROR, &amp;#34;Could not allocate output context\n&amp;#34;);
        goto _ERROR;
    }
    outFmt = av_guess_format(NULL, dst, NULL);
    if(outFmt == NULL){
        av_log(NULL, AV_LOG_ERROR, &amp;#34;Could not find %s format\n&amp;#34;, dst);
        goto _ERROR;
    }
    ofmt_ctx-&amp;gt;oformat = outFmt;
    in_stream = fmt_ctx-&amp;gt;streams[index];
    out_stream = avformat_new_stream(ofmt_ctx, NULL);
    if(out_stream == NULL){
        av_log(NULL, AV_LOG_ERROR, &amp;#34;Could not allocate output stream\n&amp;#34;);
        goto _ERROR;
    }
    avcodec_parameters_copy(out_stream-&amp;gt;codecpar, in_stream-&amp;gt;codecpar);
    // 会根据输出文件类型设置编码器
    out_stream-&amp;gt;codecpar-&amp;gt;codec_tag = 0;
    ret = avio_open2(&amp;amp;ofmt_ctx-&amp;gt;pb, dst, AVIO_FLAG_WRITE, NULL, NULL);
    if(ret &amp;lt; 0){
        av_log(NULL, AV_LOG_ERROR, &amp;#34;Could not open output file %s\n&amp;#34;, dst);
        goto _ERROR;
    }
    ret = avformat_write_header(ofmt_ctx, NULL);
    if(ret &amp;lt; 0){
        av_log(NULL, AV_LOG_ERROR, &amp;#34;Error write header \n&amp;#34;);
        goto _ERROR;
    }
    while(av_read_frame(fmt_ctx, &amp;amp;pkt) &amp;gt;= 0){
        if(pkt.stream_index == index){
            pkt.stream_index = 0;
            pkt.pts = av_rescale_q_rnd(pkt.pts, in_stream-&amp;gt;time_base, out_stream-&amp;gt;time_base, AV_ROUND_NEAR_INF|AV_ROUND_PASS_MINMAX);
            pkt.dts = pkt.dts;
            pkt.duration = av_rescale_q(pkt.duration, in_stream-&amp;gt;time_base, out_stream-&amp;gt;time_base);
            pkt.pos = -1;
            av_interleaved_write_frame(ofmt_ctx, &amp;amp;pkt);
            av_packet_unref(&amp;amp;pkt);
        }
    }
    av_write_trailer(ofmt_ctx); 

_ERROR:
    if(fmt_ctx != NULL){
        avformat_close_input(&amp;amp;fmt_ctx);
    }
    if(ofmt_ctx != NULL){
        avformat_free_context(ofmt_ctx);
    }
    if (ofmt_ctx-&amp;gt;pb)
    {
        avio_close(ofmt_ctx-&amp;gt;pb);
    }
    
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;





&lt;img class=&#34;img-fluid&#34; src=&#34;https://898311543.github.io/image-20240911005025395.png&#34; alt=&#39;image-20240911005025395&#39; /&gt;
&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;libavutil/log.h&amp;gt;
#include &amp;lt;libavutil/avutil.h&amp;gt;
#include &amp;lt;libavformat/avio.h&amp;gt;
#include &amp;lt;libavformat/avformat.h&amp;gt;

int main(int argc, char *argv[]){
    // 1、处理一些参数
    // 2、打开文件
    // 3、从多媒体文件中找到音频流
    // 4、打开目的文件的上下文
    // 5、为目的文件打开音频流
    // 6、设置输出音频参数
    // 7、写多媒体文件头
    // 8、循环读取音频流，写入目的文件
    // 9、写文件尾
    // 10、 释放资源

    char* src;
    char* dst;
    AVFormatContext *fmt_ctx=NULL, *ofmt_ctx=NULL;
    AVOutputFormat *outFmt;
    AVStream *in_stream = NULL, *out_stream = NULL;
    AVPacket pkt;
    int index = 0;
    int *stream_map = NULL;
    int i;
    av_log_set_level(AV_LOG_DEBUG);
    if (argc &amp;lt; 3) {
        printf(&amp;#34;Usage: %s &amp;lt;input file&amp;gt; &amp;lt;output file&amp;gt;\n&amp;#34;, argv[0]);
        exit(1);
    }
    src = argv[1];
    dst = argv[2];
    // 第一个null 表示相关的格式 最后一个参数为选项 如果返回值为负值表示失败
    int ret = avformat_open_input(&amp;amp;fmt_ctx, src, NULL, NULL);
    if (ret &amp;lt; 0) {
        av_log(NULL, AV_LOG_ERROR, &amp;#34;Could not open source file %s\n&amp;#34;, src);
        exit(1);
    }
    // index = av_find_best_stream(fmt_ctx, AVMEDIA_TYPE_VIDEO, -1, -1, NULL, 0);
    // if(index &amp;lt; 0){
    //     // 第一参数可以指定为上下文
    //     av_log(fmt_ctx, AV_LOG_ERROR, &amp;#34;Could not find %s stream in input file %s\n&amp;#34;, av_get_media_type_string(AVMEDIA_TYPE_AUDIO), src);
    //     goto _ERROR;
    // }
    avformat_alloc_output_context2(&amp;amp;ofmt_ctx, NULL, NULL, dst);
    if(ofmt_ctx == NULL){
        av_log(NULL, AV_LOG_ERROR, &amp;#34;Could not allocate output context\n&amp;#34;);
        goto _ERROR;
    }
    stream_map= av_calloc(fmt_ctx-&amp;gt;nb_streams, sizeof(*stream_map)); 
    if(stream_map == NULL){
        av_log(NULL, AV_LOG_ERROR, &amp;#34;Could not allocate stream map\n&amp;#34;);
        goto _ERROR;
    }
    for(i = 0; i &amp;lt; fmt_ctx-&amp;gt;nb_streams; i++){
        stream_map[i] = i;
    }   
    for (i = 0; i &amp;lt; fmt_ctx-&amp;gt;nb_streams; i++){
        in_stream = fmt_ctx-&amp;gt;streams[i];
        AVCodecParameters *inCodecPar = in_stream-&amp;gt;codecpar;
        if(inCodecPar-&amp;gt;codec_type == AVMEDIA_TYPE_AUDIO ||
           inCodecPar-&amp;gt;codec_type == AVMEDIA_TYPE_VIDEO ||
           inCodecPar-&amp;gt;codec_type == AVMEDIA_TYPE_SUBTITLE
        ){
            stream_map[i] = index++;
        }
        else{
            stream_map[i] = -1;
            continue;
        }
        out_stream = avformat_new_stream(ofmt_ctx, NULL);
        if(out_stream == NULL){
            av_log(ofmt_ctx, AV_LOG_ERROR, &amp;#34;Could not allocate output stream\n&amp;#34;);
            goto _ERROR;
        }
        avcodec_parameters_copy(out_stream-&amp;gt;codecpar, in_stream-&amp;gt;codecpar);
        // 会根据输出文件类型设置编码器
        out_stream-&amp;gt;codecpar-&amp;gt;codec_tag = 0;
    }


    ret = avio_open2(&amp;amp;ofmt_ctx-&amp;gt;pb, dst, AVIO_FLAG_WRITE, NULL, NULL);
    if(ret &amp;lt; 0){
        av_log(NULL, AV_LOG_ERROR, &amp;#34;Could not open output file %s\n&amp;#34;, dst);
        goto _ERROR;
    }
    ret = avformat_write_header(ofmt_ctx, NULL);
    if(ret &amp;lt; 0){
        av_log(NULL, AV_LOG_ERROR, &amp;#34;Error write header \n&amp;#34;);
        goto _ERROR;
    }
    while(av_read_frame(fmt_ctx, &amp;amp;pkt) &amp;gt;= 0){
        // av_log(NULL, AV_LOG_INFO, &amp;#34;pkt index = %d\n&amp;#34;, pkt.stream_index);
        pkt.stream_index = stream_map[pkt.stream_index];
        if(pkt.stream_index &amp;lt; 0){
            av_packet_unref(&amp;amp;pkt);
            continue;
        }
        av_packet_rescale_ts(&amp;amp;pkt, fmt_ctx-&amp;gt;streams[pkt.stream_index]-&amp;gt;time_base, ofmt_ctx-&amp;gt;streams[pkt.stream_index]-&amp;gt;time_base);
        pkt.pos = -1;
        av_interleaved_write_frame(ofmt_ctx, &amp;amp;pkt);
        av_packet_unref(&amp;amp;pkt);
    }
    av_write_trailer(ofmt_ctx); 

_ERROR:
    if(fmt_ctx != NULL){
        avformat_close_input(&amp;amp;fmt_ctx);
    }
    if(ofmt_ctx != NULL){
        avformat_free_context(ofmt_ctx);
    }
    if (ofmt_ctx-&amp;gt;pb)
    {
        avio_close(ofmt_ctx-&amp;gt;pb);
    }
    if (stream_map)
    {
        av_freep(&amp;amp;stream_map);
    }
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;视频裁剪&#34;&gt;视频裁剪
&lt;/h3&gt;&lt;p&gt;





&lt;img class=&#34;img-fluid&#34; src=&#34;https://898311543.github.io/image-20240912002846369.png&#34; alt=&#39;image-20240912002846369&#39; /&gt;
&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;libavutil/log.h&amp;gt;
#include &amp;lt;libavutil/avutil.h&amp;gt;
#include &amp;lt;libavformat/avio.h&amp;gt;
#include &amp;lt;libavformat/avformat.h&amp;gt;
#include &amp;lt;stdlib.h&amp;gt;

int main(int argc, char *argv[]){
    // 1、处理一些参数
    // 2、打开文件
    // 3、从多媒体文件中找到音频流
    // 4、打开目的文件的上下文
    // 5、为目的文件打开音频流
    // 6、设置输出音频参数
    // 7、写多媒体文件头
    // 8、循环读取音频流，写入目的文件
    // 9、写文件尾
    // 10、 释放资源

    char* src;
    char* dst;
    AVFormatContext *fmt_ctx=NULL, *ofmt_ctx=NULL;
    AVOutputFormat *outFmt=NULL;
    AVStream *in_stream = NULL, *out_stream = NULL;
    AVPacket pkt;
    int index = 0;
    int *stream_map = NULL;
    int i;
    av_log_set_level(AV_LOG_DEBUG);
    if (argc &amp;lt; 5) {
        printf(&amp;#34;Usage: %s &amp;lt;input file&amp;gt; &amp;lt;output file&amp;gt;\n&amp;#34;, argv[0]);
        exit(1);
    }
    src = argv[1];
    dst = argv[2];
    int starttime = atoi(argv[3]);
    int endtime = atoi(argv[4]);
    // 第一个null 表示相关的格式 最后一个参数为选项 如果返回值为负值表示失败
    int ret = avformat_open_input(&amp;amp;fmt_ctx, src, NULL, NULL);
    if (ret &amp;lt; 0) {
        av_log(NULL, AV_LOG_ERROR, &amp;#34;Could not open source file %s\n&amp;#34;, src);
        exit(1);
    }
    // index = av_find_best_stream(fmt_ctx, AVMEDIA_TYPE_VIDEO, -1, -1, NULL, 0);
    // if(index &amp;lt; 0){
    //     // 第一参数可以指定为上下文
    //     av_log(fmt_ctx, AV_LOG_ERROR, &amp;#34;Could not find %s stream in input file %s\n&amp;#34;, av_get_media_type_string(AVMEDIA_TYPE_AUDIO), src);
    //     goto _ERROR;
    // }
    avformat_alloc_output_context2(&amp;amp;ofmt_ctx, NULL, NULL, dst);
    if(ofmt_ctx == NULL){
        av_log(NULL, AV_LOG_ERROR, &amp;#34;Could not allocate output context\n&amp;#34;);
        goto _ERROR;
    }
    stream_map= av_calloc(fmt_ctx-&amp;gt;nb_streams, sizeof(*stream_map)); 
    if(stream_map == NULL){
        av_log(NULL, AV_LOG_ERROR, &amp;#34;Could not allocate stream map\n&amp;#34;);
        goto _ERROR;
    }
    for(i = 0; i &amp;lt; fmt_ctx-&amp;gt;nb_streams; i++){
        stream_map[i] = i;
    }   
    for (i = 0; i &amp;lt; fmt_ctx-&amp;gt;nb_streams; i++){
        in_stream = fmt_ctx-&amp;gt;streams[i];
        AVCodecParameters *inCodecPar = in_stream-&amp;gt;codecpar;
        if(inCodecPar-&amp;gt;codec_type == AVMEDIA_TYPE_AUDIO ||
           inCodecPar-&amp;gt;codec_type == AVMEDIA_TYPE_VIDEO ||
           inCodecPar-&amp;gt;codec_type == AVMEDIA_TYPE_SUBTITLE
        ){
            stream_map[i] = index++;
        }
        else{
            stream_map[i] = -1;
            continue;
        }
        out_stream = avformat_new_stream(ofmt_ctx, NULL);
        if(out_stream == NULL){
            av_log(ofmt_ctx, AV_LOG_ERROR, &amp;#34;Could not allocate output stream\n&amp;#34;);
            goto _ERROR;
        }
        avcodec_parameters_copy(out_stream-&amp;gt;codecpar, in_stream-&amp;gt;codecpar);
        // 会根据输出文件类型设置编码器
        out_stream-&amp;gt;codecpar-&amp;gt;codec_tag = 0;
    }

    ret = avio_open2(&amp;amp;ofmt_ctx-&amp;gt;pb, dst, AVIO_FLAG_WRITE, NULL, NULL);
    if(ret &amp;lt; 0){
        av_log(NULL, AV_LOG_ERROR, &amp;#34;Could not open output file %s\n&amp;#34;, dst);
        goto _ERROR;
    }
    ret = avformat_write_header(ofmt_ctx, NULL);
    if(ret &amp;lt; 0){
        av_log(NULL, AV_LOG_ERROR, &amp;#34;Error write header \n&amp;#34;);
        goto _ERROR;
    }
    int64_t *dst_start_time_pts = av_calloc(ofmt_ctx-&amp;gt;nb_streams, sizeof(int64_t));
    int64_t *dst_start_time_dts = av_calloc(ofmt_ctx-&amp;gt;nb_streams, sizeof(int64_t));
    for(i = 0; i &amp;lt; fmt_ctx-&amp;gt;nb_streams; i++){
        dst_start_time_pts[i] = -1;
        dst_start_time_dts[i] = -1;
    }

    ret = av_seek_frame(fmt_ctx, -1, starttime * AV_TIME_BASE, AVSEEK_FLAG_BACKWARD);
    if(ret &amp;lt; 0){
        av_log(NULL, AV_LOG_ERROR, &amp;#34;Error seek frame \n&amp;#34;);
        goto _ERROR;
    }
    while(av_read_frame(fmt_ctx, &amp;amp;pkt) &amp;gt;= 0){
        if(av_q2d(fmt_ctx-&amp;gt;streams[pkt.stream_index]-&amp;gt;time_base) * pkt.pts &amp;gt; endtime ){
            av_packet_unref(&amp;amp;pkt);
            break;
        }
        pkt.stream_index = stream_map[pkt.stream_index];
        if(dst_start_time_pts[pkt.stream_index] == -1 &amp;amp;&amp;amp; pkt.pts &amp;gt; 0){
            dst_start_time_pts[pkt.stream_index] = pkt.pts;
        }
        if(dst_start_time_dts[pkt.stream_index] == -1 &amp;amp;&amp;amp; pkt.dts &amp;gt; 0){
            dst_start_time_dts[pkt.stream_index] = pkt.dts;
        }
        pkt.pts = pkt.pts - dst_start_time_pts[pkt.stream_index];
        pkt.dts = pkt.dts - dst_start_time_dts[pkt.stream_index];
        if (pkt.pts &amp;lt; pkt.dts) {
            pkt.pts = pkt.dts;
        }
        av_log(NULL, AV_LOG_DEBUG, &amp;#34;pkt.pts = %lld, pkt.dts = %lld, pkt.stream_index = %d\n&amp;#34;, pkt.pts, pkt.dts, pkt.stream_index);

        if(pkt.stream_index &amp;lt; 0){
            av_packet_unref(&amp;amp;pkt);
            continue;
        }
        av_packet_rescale_ts(&amp;amp;pkt, fmt_ctx-&amp;gt;streams[pkt.stream_index]-&amp;gt;time_base, ofmt_ctx-&amp;gt;streams[pkt.stream_index]-&amp;gt;time_base);
        pkt.pos = -1;
        av_interleaved_write_frame(ofmt_ctx, &amp;amp;pkt);
        av_packet_unref(&amp;amp;pkt);
    }
    av_write_trailer(ofmt_ctx); 

_ERROR:
    if(fmt_ctx != NULL){
        avformat_close_input(&amp;amp;fmt_ctx);
    }
    if(ofmt_ctx != NULL){
        avformat_free_context(ofmt_ctx);
    }
    if (ofmt_ctx-&amp;gt;pb)
    {
        avio_close(ofmt_ctx-&amp;gt;pb);
    }
    if (stream_map)
    {
        av_freep(&amp;amp;stream_map);
    }
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;</description>
        </item>
        
    </channel>
</rss>
